{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T20:31:40.986548Z",
     "start_time": "2020-04-25T20:31:40.747827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1207, Built 952, Cleaned 879, Transferred 879\n",
      "Not downloaded 227, Not built 188, Not cleaned 0, Not transferred 0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import urllib\n",
    "prefix = '/Users/dd/Downloads/.metagraph_run36/'\n",
    "\n",
    "fServer = open(f'{prefix}/server.log')\n",
    "lines = fServer.readlines()\n",
    "\n",
    "downloaded_sras = set()\n",
    "build_sras = set()\n",
    "clean_sras = set()\n",
    "transfer_sras = set()\n",
    "ndownloaded_sras = set()\n",
    "nbuild_sras = set()\n",
    "nclean_sras = set()\n",
    "ntransfer_sras = set()\n",
    "time_first = 0\n",
    "time_last = 0\n",
    "for l in lines:\n",
    "    if not 'ack/' in l:\n",
    "        continue\n",
    "    split_l = l.split(' ')\n",
    "    date_time = datetime.datetime.strptime(split_l[0] + ' ' + split_l[1], '%Y-%m-%d %H:%M:%S,%f')\n",
    "    parsed = urllib.parse.parse_qs(split_l[4])\n",
    "    \n",
    "    sra_id = parsed['id'][0]\n",
    "    if time_first == 0:\n",
    "        time_first = date_time\n",
    "    time_last = date_time\n",
    "    if '/ack/download' in l:\n",
    "        downloaded_sras.add(sra_id)\n",
    "    elif '/ack/build' in l:\n",
    "        build_sras.add(sra_id)\n",
    "    elif '/ack/clean' in l:\n",
    "        clean_sras.add(sra_id)\n",
    "    elif '/ack/transfer' in l:\n",
    "        transfer_sras.add(sra_id)\n",
    "    elif '/nack/download' in l:\n",
    "        ndownloaded_sras.add(sra_id)\n",
    "    elif '/nack/build' in l:\n",
    "        nbuild_sras.add(sra_id)\n",
    "    elif '/nack/clean' in l:\n",
    "        nclean_sras.add(sra_id)\n",
    "    elif '/nack/transfer' in l:\n",
    "        ntransfer_sras.add(sra_id)\n",
    "\n",
    "# remove SRAs that were re-tried and successfully processed after an initial failure\n",
    "ndownloaded_sras = ndownloaded_sras.difference(downloaded_sras)\n",
    "nbuild_sras = nbuild_sras.difference(build_sras)\n",
    "nclean_sras = nclean_sras.difference(clean_sras)\n",
    "print(f'Downloaded {len(downloaded_sras)}, Built {len(build_sras)}, Cleaned {len(clean_sras)}, Transferred {len(transfer_sras)}')\n",
    "print(f'Not downloaded {len(ndownloaded_sras)}, Not built {len(nbuild_sras)}, Not cleaned {len(nclean_sras)}, Not transferred {len(ntransfer_sras)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T20:34:20.861078Z",
     "start_time": "2020-04-25T20:34:20.796468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of all SRAs, including not downloaded: 2380175.43MB\n",
      "Total size of downloaded SRAS: 1778889.35MB\n",
      "Total download size (of finished SRAs): 1120246.95MB\n",
      "Total not downloaded size: 1259928.48MB\n",
      "Total download time (of finished SRAs): 355959s\n",
      "Download bandwidth (of finished SRAs): 3.15MB/s/machine\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import urllib.parse\n",
    "\n",
    "download_size_processed = 0\n",
    "ndownload_size = 0\n",
    "download_size_downloaded = 0\n",
    "size_all = 0\n",
    "download_size_processed_hist = defaultdict(int)\n",
    "download_size_processeds = []\n",
    "download_time = 0\n",
    "sra_to_size = {}\n",
    "ndownload_size_hist = defaultdict(int)\n",
    "coverage = []\n",
    "coverage_size = []\n",
    "coverage_total_size = 0\n",
    "seen_acks = set()\n",
    "seen_nacks = set()\n",
    "for l in lines:\n",
    "    if not 'ack/down' in l:\n",
    "        continue\n",
    "    parsed = urllib.parse.parse_qs(l.split(' ')[4])\n",
    "    sra_id = parsed['id'][0]\n",
    "    size = float(parsed['size_mb'][0])\n",
    "    \n",
    "    if '/ack/download' in l and sra_id in downloaded_sras:\n",
    "        if sra_id in seen_acks:\n",
    "            continue\n",
    "        seen_acks.add(sra_id)\n",
    "        kmer_coverage = float(parsed['kmer_coverage'][0])\n",
    "        unique_kmers = float(parsed['kmer_count_unique'][0])\n",
    "        coverage.append(int(kmer_coverage))\n",
    "        coverage_size.append(size)\n",
    "        coverage_total_size += size\n",
    "        download_size_processed_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "        download_size_processeds.append(size/1e3)\n",
    "        sra_to_size[sra_id] = size\n",
    "        download_size_downloaded += size\n",
    "        \n",
    "        if sra_id in transfer_sras:\n",
    "            download_time += int(l.split('&')[2].split('=')[1])\n",
    "            download_size_processed += size\n",
    "    elif '/nack/download' in l and sra_id in ndownloaded_sras:\n",
    "        if sra_id in seen_nacks:  # download attempt that failed twice (e.g. after a re-process of failed downloads)\n",
    "            continue\n",
    "        seen_nacks.add(sra_id)\n",
    "        ndownload_size_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "        size_all += size\n",
    "        ndownload_size += size\n",
    "size_all += download_size_processed\n",
    "print(f'Total size of all SRAs, including not downloaded: {round(size_all,2)}MB')\n",
    "print(f'Total size of downloaded SRAS: {round(download_size_downloaded,2)}MB')\n",
    "print(f'Total download size (of finished SRAs): {round(download_size_processed,2)}MB')\n",
    "print(f'Total not downloaded size: {round(ndownload_size,2)}MB')\n",
    "print(f'Total download time (of finished SRAs): {download_time}s')\n",
    "print(f'Download bandwidth (of finished SRAs): {round(download_size_processed/download_time,2)}MB/s/machine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T20:34:22.248023Z",
     "start_time": "2020-04-25T20:34:22.227737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total build time (of finished SRAs): 2116072.0s\n",
      "Total build size (of finished SRAs): 12245943.34MB\n",
      "Total size of too large SRAs:  0\n",
      "Build bandwidth is 0.572730426941994MB/s\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "size_download = 0\n",
    "size_build = 0\n",
    "build_size_hist = defaultdict(int)\n",
    "build_sizes = []\n",
    "build_size_to_time = {}\n",
    "nbuild_size_hist = defaultdict(int)\n",
    "nbuild_sizes = []\n",
    "too_large = 0\n",
    "\n",
    "for d in lines:\n",
    "    if not 'ack/build' in d:\n",
    "        continue\n",
    "    if '/ack/build' in d:\n",
    "        sra_id = d.split('&')[1].split('=')[1]\n",
    "        sz = sra_to_size[sra_id] #float(d.split('&')[4].split('=')[1])\n",
    "        build_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        build_sizes.append(sz/1e3)\n",
    "        tm = float(d.split('&')[2].split('=')[1])\n",
    "        size_build += float(d.split('&')[4].split('=')[1])\n",
    "        build_size_to_time[sz] = tm\n",
    "        if sra_id in transfer_sras:\n",
    "            time = time + tm\n",
    "            size_download += sz\n",
    "    elif '/nack/build' in d:\n",
    "        sz = sra_to_size[sra_id]\n",
    "        nbuild_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        nbuild_sizes.append(sz/1e3)\n",
    "        if 'required_ram_gb' in d:\n",
    "            too_large += sz\n",
    "\n",
    "print(f'Total build time (of finished SRAs): {time}s')\n",
    "print(f'Total build size (of finished SRAs): {round(size_build,2)}MB')\n",
    "print(f'Total size of too large SRAs: ', too_large)\n",
    "print(f'Build bandwidth is {size_download/time}MB/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T20:34:26.198086Z",
     "start_time": "2020-04-25T20:34:26.187674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean time (of finished SRAs): 6635018.0s\n",
      "Clean bandwidth is 1120246.9500000007 6635018.0 0.17MB/s\n",
      "Compression factor is 1.6657670781255156\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "clean_size = 0\n",
    "for d in lines:\n",
    "    if not 'ack/clean' in d:\n",
    "        continue\n",
    "    sra_id = d.split('&')[1].split('=')[1]\n",
    "    if sra_id in transfer_sras:\n",
    "        time = time + float(d.split('&')[2].split('=')[1])\n",
    "        clean_size = clean_size + float(d.split('&')[3].split('=')[1])\n",
    "        \n",
    "    \n",
    "print(f'Total clean time (of finished SRAs): {time}s')\n",
    "print (f'Clean bandwidth is {download_size_processed} {time} {round(download_size_processed/time,2)}MB/s')\n",
    "print(f'Compression factor is {download_size_processed/clean_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:22:52.930832Z",
     "start_time": "2020-04-26T15:22:52.927826Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.bar(list(download_size_processed_hist.keys()), download_size_processed_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download successful)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.bar(list(ndownload_size_hist.keys()), ndownload_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download failed)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(download_size_processeds, bins=range(0,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:19:01.769626Z",
     "start_time": "2020-04-07T13:19:01.743Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.bar(list(build_size_hist.keys()), build_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build successful)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.bar(list(nbuild_size_hist.keys()), nbuild_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build failed)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.title('SRA histogram')\n",
    "# plt.hist(build_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# plt.hist(nbuild_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.title('Build time by size')\n",
    "# od = collections.OrderedDict(sorted(build_size_to_time.items()))\n",
    "# # plt.plot(list(od.keys()), list(od.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:19:01.771339Z",
     "start_time": "2020-04-07T13:19:01.744Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.title('K-mer coverage')\n",
    "# plt.hist(coverage, bins=range(0,40), weights=coverage_size, density=True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
