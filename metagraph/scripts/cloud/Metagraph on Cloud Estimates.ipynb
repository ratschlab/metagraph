{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T06:08:16.952399Z",
     "start_time": "2020-04-03T06:08:16.841795Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 791, Built 727, Cleaned 726, Transferred 726\n",
      "Not downloaded 178, Not built 64, Not cleaned 0, Not transferred 0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "prefix = '/Users/dd/Downloads/.metagraph_run16/'\n",
    "\n",
    "fServer = open(f'{prefix}/server.log')\n",
    "lines = fServer.readlines()\n",
    "\n",
    "downloaded_sras = set()\n",
    "build_sras = set()\n",
    "clean_sras = set()\n",
    "transfer_sras = set()\n",
    "ndownloaded_sras = set()\n",
    "nbuild_sras = set()\n",
    "nclean_sras = set()\n",
    "ntransfer_sras = set()\n",
    "time_first = 0\n",
    "time_last = 0\n",
    "for l in lines:\n",
    "    if not 'ack' in l:\n",
    "        continue\n",
    "    split_l = l.split(' ')\n",
    "    date_time = datetime.datetime.strptime(split_l[0] + ' ' + split_l[1], '%Y-%m-%d %H:%M:%S,%f')\n",
    "    parsed = urllib.parse.parse_qs(split_l[4])\n",
    "    sra_id = parsed['id'][0]\n",
    "    if time_first == 0:\n",
    "        time_first = date_time\n",
    "    time_last = date_time\n",
    "    if '/ack/download' in l:\n",
    "        downloaded_sras.add(sra_id)\n",
    "    elif '/ack/build' in l:\n",
    "        build_sras.add(sra_id)\n",
    "    elif '/ack/clean' in l:\n",
    "        clean_sras.add(sra_id)\n",
    "    elif '/ack/transfer' in l:\n",
    "        transfer_sras.add(sra_id)\n",
    "    elif '/nack/download' in l:\n",
    "        ndownloaded_sras.add(sra_id)\n",
    "    elif '/nack/build' in l:\n",
    "        nbuild_sras.add(sra_id)\n",
    "    elif '/nack/clean' in l:\n",
    "        nclean_sras.add(sra_id)\n",
    "    elif '/nack/transfer' in l:\n",
    "        ntransfer_sras.add(sra_id)\n",
    "    \n",
    "print(f'Downloaded {len(downloaded_sras)}, Built {len(build_sras)}, Cleaned {len(clean_sras)}, Transferred {len(transfer_sras)}')\n",
    "print(f'Not downloaded {len(ndownloaded_sras)}, Not built {len(nbuild_sras)}, Not cleaned {len(nclean_sras)}, Not transferred {len(ntransfer_sras)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T05:54:18.028961Z",
     "start_time": "2020-04-03T05:54:17.995915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total download size (of finished SRAs): 468096.21MB\n",
      "Total download time (of finished SRAs): 97660s\n",
      "Download bandwidth (of finished SRAs): 4.79MB/s/machine\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import urllib.parse\n",
    "\n",
    "download_size = 0\n",
    "download_size_hist = defaultdict(int)\n",
    "download_sizes = []\n",
    "download_time = 0\n",
    "sra_to_size = {}\n",
    "ndownload_size_hist = defaultdict(int)\n",
    "coverage = []\n",
    "coverage_size = []\n",
    "coverage_total_size = 0\n",
    "\n",
    "for l in lines:\n",
    "    if not 'ack/down' in l:\n",
    "        continue\n",
    "    parsed = urllib.parse.parse_qs(l.split(' ')[4])\n",
    "    sra_id = parsed['id'][0]\n",
    "    size = float(parsed['size_mb'][0])\n",
    "    \n",
    "    if '/ack/download' in l:\n",
    "        total_kmers = float(parsed['kmer_count_total'][0])\n",
    "        unique_kmers = float(parsed['kmer_count_unique'][0])\n",
    "        coverage.append(int(total_kmers/unique_kmers) if unique_kmers >0 else 0)\n",
    "        coverage_size.append(size)\n",
    "        coverage_total_size += size\n",
    "        download_size_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "        download_sizes.append(size/1e3)\n",
    "        sra_to_size[sra_id] = size\n",
    "        \n",
    "        if sra_id in transfer_sras:\n",
    "            download_time += int(l.split('&')[2].split('=')[1])\n",
    "            download_size = download_size + size\n",
    "    elif '/nack/download' in l:\n",
    "        ndownload_size_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "print(f'Total download size (of finished SRAs): {round(download_size,2)}MB')\n",
    "print(f'Total download time (of finished SRAs): {download_time}s')\n",
    "print(f'Download bandwidth (of finished SRAs): {round(download_size/download_time,2)}MB/s/machine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T05:54:18.627087Z",
     "start_time": "2020-04-03T05:54:18.612997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total build time (of finished SRAs): 273785.0s\n",
      "Total build size (of finished SRAs): 902311.9599999994MB\n",
      "Build bandwidth is 1.7097218985700469MB/s\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "size_download = 0\n",
    "size_build = 0\n",
    "build_size_hist = defaultdict(int)\n",
    "build_sizes = []\n",
    "build_size_to_time = {}\n",
    "nbuild_size_hist = defaultdict(int)\n",
    "nbuild_sizes = []\n",
    "\n",
    "for d in lines:\n",
    "    if not 'ack/build' in d:\n",
    "        continue\n",
    "    if '/ack/build' in d:\n",
    "        sra_id = d.split('&')[1].split('=')[1]\n",
    "        sz = sra_to_size[sra_id] #float(d.split('&')[4].split('=')[1])\n",
    "        build_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        build_sizes.append(sz/1e3)\n",
    "        tm = float(d.split('&')[2].split('=')[1])\n",
    "        size_build += float(d.split('&')[4].split('=')[1])\n",
    "        build_size_to_time[sz] = tm\n",
    "        if sra_id in transfer_sras:\n",
    "            time = time + tm\n",
    "            size_download += sz\n",
    "    elif '/nack/build' in d:\n",
    "        sz = sra_to_size[sra_id]\n",
    "        nbuild_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        nbuild_sizes.append(sz/1e3)\n",
    "\n",
    "print(f'Total build time (of finished SRAs): {time}s')\n",
    "print(f'Total build size (of finished SRAs): {size_build}MB')\n",
    "print(f'Build bandwidth is {size_download/time}MB/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T06:08:21.755140Z",
     "start_time": "2020-04-03T06:08:21.745425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean time (of finished SRAs): 310123.0s\n",
      "Clean bandwidth is 468096.2100000002 310123.0 1.51MB/s\n",
      "Compression factor is 37.58975600589748\n",
      "Overall processing bandwidth is 0.030636827843575135\n",
      "2020-04-02 19:26:41.313000 2020-04-02 15:27:40.330000\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "clean_size = 0\n",
    "for d in lines:\n",
    "    if not 'ack/clean' in d:\n",
    "        continue\n",
    "    sra_id = d.split('&')[1].split('=')[1]\n",
    "    if sra_id in transfer_sras:\n",
    "        time = time + float(d.split('&')[2].split('=')[1])\n",
    "        clean_size = clean_size + float(d.split('&')[3].split('=')[1])\n",
    "        \n",
    "    \n",
    "print(f'Total clean time (of finished SRAs): {time}s')\n",
    "print (f'Clean bandwidth is {download_size} {time} {round(download_size/time,2)}MB/s')\n",
    "print(f'Compression factor is {download_size/clean_size}')\n",
    "print(f'Overall processing bandwidth is {(time_last-time_first).total_seconds()/download_size}')\n",
    "print(time_last, time_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T16:30:19.895939Z",
     "start_time": "2020-04-03T16:30:19.893321Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.bar(list(download_size_hist.keys()), download_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download successful)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.bar(list(ndownload_size_hist.keys()), ndownload_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download failed)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(download_sizes, bins=range(0,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T05:42:33.599050Z",
     "start_time": "2020-04-03T05:42:33.595652Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.bar(list(build_size_hist.keys()), build_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build successful)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.bar(list(nbuild_size_hist.keys()), nbuild_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build failed)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.title('SRA histogram')\n",
    "# plt.hist(build_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# plt.hist(nbuild_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.title('Build time by size')\n",
    "# od = collections.OrderedDict(sorted(build_size_to_time.items()))\n",
    "# # plt.plot(list(od.keys()), list(od.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T05:42:33.604737Z",
     "start_time": "2020-04-03T05:42:33.601786Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.title('K-mer coverage')\n",
    "# plt.hist(coverage, bins=range(0,40), weights=coverage_size, density=True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
