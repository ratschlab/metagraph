{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T20:25:57.671741Z",
     "start_time": "2020-04-16T20:25:49.768439Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 71917, Built 71514, Cleaned 71506, Transferred 71506\n",
      "Not downloaded 2795, Not built 398, Not cleaned 0, Not transferred 0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import urllib\n",
    "prefix = '/Users/dd/Downloads/.metagraph_run33/'\n",
    "\n",
    "fServer = open(f'{prefix}/server.log')\n",
    "lines = fServer.readlines()\n",
    "\n",
    "downloaded_sras = set()\n",
    "build_sras = set()\n",
    "clean_sras = set()\n",
    "transfer_sras = set()\n",
    "ndownloaded_sras = set()\n",
    "nbuild_sras = set()\n",
    "nclean_sras = set()\n",
    "ntransfer_sras = set()\n",
    "time_first = 0\n",
    "time_last = 0\n",
    "for l in lines:\n",
    "    if not 'ack' in l:\n",
    "        continue\n",
    "    split_l = l.split(' ')\n",
    "    date_time = datetime.datetime.strptime(split_l[0] + ' ' + split_l[1], '%Y-%m-%d %H:%M:%S,%f')\n",
    "    parsed = urllib.parse.parse_qs(split_l[4])\n",
    "    sra_id = parsed['id'][0]\n",
    "    if time_first == 0:\n",
    "        time_first = date_time\n",
    "    time_last = date_time\n",
    "    if '/ack/download' in l:\n",
    "        downloaded_sras.add(sra_id)\n",
    "    elif '/ack/build' in l:\n",
    "        build_sras.add(sra_id)\n",
    "    elif '/ack/clean' in l:\n",
    "        clean_sras.add(sra_id)\n",
    "    elif '/ack/transfer' in l:\n",
    "        transfer_sras.add(sra_id)\n",
    "    elif '/nack/download' in l:\n",
    "        ndownloaded_sras.add(sra_id)\n",
    "    elif '/nack/build' in l:\n",
    "        nbuild_sras.add(sra_id)\n",
    "    elif '/nack/clean' in l:\n",
    "        nclean_sras.add(sra_id)\n",
    "    elif '/nack/transfer' in l:\n",
    "        ntransfer_sras.add(sra_id)\n",
    "    \n",
    "print(f'Downloaded {len(downloaded_sras)}, Built {len(build_sras)}, Cleaned {len(clean_sras)}, Transferred {len(transfer_sras)}')\n",
    "print(f'Not downloaded {len(ndownloaded_sras)}, Not built {len(nbuild_sras)}, Not cleaned {len(nclean_sras)}, Not transferred {len(ntransfer_sras)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T20:26:35.394267Z",
     "start_time": "2020-04-16T20:26:33.917384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total download size (of finished SRAs): 42968024.5MB\n",
      "Total download time (of finished SRAs): 8884976s\n",
      "Download bandwidth (of finished SRAs): 4.84MB/s/machine\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import urllib.parse\n",
    "\n",
    "download_size = 0\n",
    "download_size_hist = defaultdict(int)\n",
    "download_sizes = []\n",
    "download_time = 0\n",
    "sra_to_size = {}\n",
    "ndownload_size_hist = defaultdict(int)\n",
    "coverage = []\n",
    "coverage_size = []\n",
    "coverage_total_size = 0\n",
    "\n",
    "for l in lines:\n",
    "    if not 'ack/down' in l:\n",
    "        continue\n",
    "    parsed = urllib.parse.parse_qs(l.split(' ')[4])\n",
    "    sra_id = parsed['id'][0]\n",
    "    size = float(parsed['size_mb'][0])\n",
    "    \n",
    "    if '/ack/download' in l:\n",
    "        kmer_coverage = float(parsed['kmer_coverage'][0])\n",
    "        unique_kmers = float(parsed['kmer_count_unique'][0])\n",
    "        coverage.append(int(kmer_coverage))\n",
    "        coverage_size.append(size)\n",
    "        coverage_total_size += size\n",
    "        download_size_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "        download_sizes.append(size/1e3)\n",
    "        sra_to_size[sra_id] = size\n",
    "        \n",
    "        if sra_id in transfer_sras:\n",
    "            download_time += int(l.split('&')[2].split('=')[1])\n",
    "            download_size = download_size + size\n",
    "    elif '/nack/download' in l:\n",
    "        ndownload_size_hist[int(size/100) if int(size/100)<200 else 200] += 1\n",
    "print(f'Total download size (of finished SRAs): {round(download_size,2)}MB')\n",
    "print(f'Total download time (of finished SRAs): {download_time}s')\n",
    "print(f'Download bandwidth (of finished SRAs): {round(download_size/download_time,2)}MB/s/machine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T20:26:41.580509Z",
     "start_time": "2020-04-16T20:26:41.205355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total build time (of finished SRAs): 5976542.0s\n",
      "Total build size (of finished SRAs): 14948430.130000051MB\n",
      "Build bandwidth is 7.1894457530793305MB/s\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "size_download = 0\n",
    "size_build = 0\n",
    "build_size_hist = defaultdict(int)\n",
    "build_sizes = []\n",
    "build_size_to_time = {}\n",
    "nbuild_size_hist = defaultdict(int)\n",
    "nbuild_sizes = []\n",
    "\n",
    "for d in lines:\n",
    "    if not 'ack/build' in d:\n",
    "        continue\n",
    "    if '/ack/build' in d:\n",
    "        sra_id = d.split('&')[1].split('=')[1]\n",
    "        sz = sra_to_size[sra_id] #float(d.split('&')[4].split('=')[1])\n",
    "        build_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        build_sizes.append(sz/1e3)\n",
    "        tm = float(d.split('&')[2].split('=')[1])\n",
    "        size_build += float(d.split('&')[4].split('=')[1])\n",
    "        build_size_to_time[sz] = tm\n",
    "        if sra_id in transfer_sras:\n",
    "            time = time + tm\n",
    "            size_download += sz\n",
    "    elif '/nack/build' in d:\n",
    "        sz = sra_to_size[sra_id]\n",
    "        nbuild_size_hist[int(sz/100) if int(sz/100)<200 else 200] += 1\n",
    "        nbuild_sizes.append(sz/1e3)\n",
    "\n",
    "print(f'Total build time (of finished SRAs): {time}s')\n",
    "print(f'Total build size (of finished SRAs): {size_build}MB')\n",
    "print(f'Build bandwidth is {size_download/time}MB/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T20:26:45.921703Z",
     "start_time": "2020-04-16T20:26:45.677366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean time (of finished SRAs): 13436753.0s\n",
      "Clean bandwidth is 42968024.5000002 13436753.0 3.2MB/s\n",
      "Compression factor is 42.3576248639823\n",
      "Overall processing bandwidth is 0.0017624621536882538\n",
      "2020-04-16 18:51:48.289000 2020-04-15 21:49:38.772000\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "clean_size = 0\n",
    "for d in lines:\n",
    "    if not 'ack/clean' in d:\n",
    "        continue\n",
    "    sra_id = d.split('&')[1].split('=')[1]\n",
    "    if sra_id in transfer_sras:\n",
    "        time = time + float(d.split('&')[2].split('=')[1])\n",
    "        clean_size = clean_size + float(d.split('&')[3].split('=')[1])\n",
    "        \n",
    "    \n",
    "print(f'Total clean time (of finished SRAs): {time}s')\n",
    "print (f'Clean bandwidth is {download_size} {time} {round(download_size/time,2)}MB/s')\n",
    "print(f'Compression factor is {download_size/clean_size}')\n",
    "print(f'Overall processing bandwidth is {(time_last-time_first).total_seconds()/download_size}')\n",
    "print(time_last, time_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:19:01.767853Z",
     "start_time": "2020-04-07T13:19:01.741Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.bar(list(download_size_hist.keys()), download_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download successful)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.bar(list(ndownload_size_hist.keys()), ndownload_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (download failed)')\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(download_sizes, bins=range(0,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:19:01.769626Z",
     "start_time": "2020-04-07T13:19:01.743Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.bar(list(build_size_hist.keys()), build_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build successful)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.bar(list(nbuild_size_hist.keys()), nbuild_size_hist.values(), color='g')\n",
    "# plt.ylabel('count')\n",
    "# plt.xlabel('size (100s of MB)')\n",
    "# plt.title('SRA distribution by size (build failed)')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.title('SRA histogram')\n",
    "# plt.hist(build_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# plt.hist(nbuild_sizes, bins=[0, 10, 20, 30, 40, 50])\n",
    "# #plt.show()\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.title('Build time by size')\n",
    "# od = collections.OrderedDict(sorted(build_size_to_time.items()))\n",
    "# # plt.plot(list(od.keys()), list(od.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:19:01.771339Z",
     "start_time": "2020-04-07T13:19:01.744Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.title('K-mer coverage')\n",
    "# plt.hist(coverage, bins=range(0,40), weights=coverage_size, density=True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
